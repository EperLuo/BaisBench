{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script for task2 of AISBench. This script includes downloading the dataset, obtaining the background information, and getting the multiple-choice question and their reference answers. You can fed these to the AI scientists and ask them to answer the question based on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_id = 2\n",
    "\n",
    "df = pd.read_excel('Task2_data/BAISBench_task2.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "question_name = df['name'][question_id]\n",
    "background_info = df[df['name']==question_name]['background'].values.item()\n",
    "\n",
    "question_list = []\n",
    "question_answer = []\n",
    "for i in range(1,6):\n",
    "    question_list.append(df[df['name']==question_name][f'Questions{i}'].values.item())\n",
    "    answers = re.findall(r'\\b([A-Z])\\)', df[df['name']==question_name][f'Answer{i}'].values.item())\n",
    "    question_answer.append(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_repo_files, hf_hub_download\n",
    "\n",
    "# 设置 repo 名称\n",
    "repo_id = \"EperLuo/BAISBench\" \n",
    "repo_type = \"dataset\" \n",
    "\n",
    "# 设置前缀\n",
    "prefix = f\"task2 - {question_name}\"\n",
    "\n",
    "# 列出所有文件\n",
    "all_files = list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "\n",
    "# 筛选出带有指定前缀的文件\n",
    "target_files = [f for f in all_files if f.startswith(prefix)]\n",
    "\n",
    "# 下载这些文件\n",
    "for file_name in target_files:\n",
    "    local_path = hf_hub_download(\n",
    "        repo_id=repo_id, \n",
    "        filename=file_name, \n",
    "        repo_type=repo_type,\n",
    "        local_dir=\"Task2_data\", \n",
    "        local_dir_use_symlinks=False )\n",
    "    print(f\"Downloaded: {file_name} -> {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how to run the Aviary framework on the Task2. We first need to format the questions and dataset into Aviary's required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "df = pd.read_excel('Task2_data/BAISBench_task2.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_map = {'A':1, 'B':2, 'C':3, 'D':4}\n",
    "for i in range(df.shape[0]):\n",
    "    problem = {}\n",
    "    name = df['name'][i]\n",
    "    problem['uuid'] = name\n",
    "    problem['short_id'] = f'AISB-{i}'\n",
    "    problem['hypothesis'] = df['background'][i]\n",
    "    problem['result'] = 'The dataset information are provided in the hypothesis.'\n",
    "    problem['answer'] = True\n",
    "    problem['categories'] = \"['RNA-seq', 'Differential Expression Analysis', 'Transcriptomics', 'Network Biology']\"\n",
    "    problem['paper'] = df['doi'][i]\n",
    "    problem['questions'] = []\n",
    "    for k in range(1,6):\n",
    "        ques = {}\n",
    "        ques['id'] = f'q{k}'\n",
    "        ques['development'] = ''\n",
    "        if pd.isna(df[f'Questions{k}'][i]):\n",
    "            continue\n",
    "        question = df[f'Questions{k}'][i].split('\\n')\n",
    "        question = [it for it in question if it!='']\n",
    "        ques['question'] = question[0]\n",
    "        options = re.findall(r'\\b([A-Z])\\)', df[f'Answer{k}'][i])\n",
    "        if len(options)>1:\n",
    "            ques['question'] += 'This question has more than one ideal answer.'\n",
    "        ques[f'ideal_answer'] = question[option_map['A']]\n",
    "        for id, opt in enumerate(['B','C','D']):\n",
    "            ques[f'distractor_{id+1}'] = question[option_map[opt]]\n",
    "        ques['explanation'] = '' \n",
    "        problem['questions'].append(ques)\n",
    "    problem['questions'] = str(problem['questions'])\n",
    "    problem['data_folder'] = name + '.zip'\n",
    "\n",
    "    with open(f'./aviary/BAIS-SD/{name}.json', 'w') as f:\n",
    "        json.dump(problem, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'Task2_data/'         # the path where you place the downloaded .h5ad files\n",
    "output_dir = 'aviary/data/capsules'       # the path where aviary will take the data\n",
    "\n",
    "# read all .h5ad file\n",
    "all_files = [f for f in os.listdir(input_dir) if f.endswith('.h5ad')]\n",
    "\n",
    "def get_dataset_prefix(filename):\n",
    "    name = filename.replace('.h5ad', '').replace('task2 - ', '')\n",
    "    prefix = name.split(' - ')[0]\n",
    "    return prefix.strip()\n",
    "\n",
    "# Iterate through all files and categorize them by prefix\n",
    "for file in all_files:\n",
    "    prefix = get_dataset_prefix(file)\n",
    "    source_path = os.path.join(input_dir, file)\n",
    "    dest_folder = os.path.join(output_dir, prefix)\n",
    "    dest_path = os.path.join(dest_folder, file)\n",
    "\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    shutil.copy2(source_path, dest_path)\n",
    "    print(f\"Copied: {file} → {dest_folder}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run the multi-agent framework to solve the questions. \n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "cd aviary\n",
    "pip install -e .\n",
    "# Pull the docker image\n",
    "docker pull futurehouse/bixbench:aviary-notebook-env\n",
    "```\n",
    "\n",
    "You can refer to FutureHouse's original [code repo](https://github.com/Future-House/BixBench) for more details. Modify the `aviary/bixbench/run_configuration/generate_trajectories.yaml` file.\n",
    "\n",
    "```bash\n",
    "sh run_generate_trajectory.sh\n",
    "```\n",
    "\n",
    "The results will be saved in `aviary/data/trajectories`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiscientist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
